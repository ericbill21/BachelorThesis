python Code/main.py --batch_size=33 --dataset=NCI1 --encoding_kwargs="{'embedding_dim': 64}" --k_fold=10 --k_wl=3 --lr=0.024871674248798253 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.038663816953314514, 'norm': 'batch_norm', 'num_layers': 2}" --model=1WL+NN:Embedding-Mean --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=33 --dataset=NCI1 --encoding_kwargs="{'embedding_dim': 32}" --k_fold=10 --k_wl=3 --lr=0.01329617178644451 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.12116916436590013, 'norm': 'batch_norm', 'num_layers': 2}" --model=1WL+NN:Embedding-Sum --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=129 --dataset=NCI1 --gnn_kwargs="{'act': 'relu', 'act_first': False, 'dropout': 0.0, 'hidden_channels': 128, 'jk': 'cat', 'norm': None, 'num_layers': 5}" --k_fold=10 --k_wl=1 --lr=0.0002710194167602541 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.024331698859625252, 'norm': 'batch_norm', 'num_layers': 4}" --model=GIN:Max --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=129 --dataset=NCI1 --gnn_kwargs="{'act': 'relu', 'act_first': False, 'dropout': 4.628116958088624e-05, 'hidden_channels': 64, 'jk': 'cat', 'norm': None, 'num_layers': 5}" --k_fold=10 --lr=0.0035933769974281333 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.06353618243833976, 'norm': 'batch_norm', 'num_layers': 4}" --model=GIN:Mean --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=33 --dataset=NCI1 --gnn_kwargs="{'act': 'relu', 'act_first': False, 'dropout': 0.1995655254085076, 'hidden_channels': 16, 'jk': 'cat', 'norm': None, 'num_layers': 5}" --k_fold=10 --lr=0.01002693091446477 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.18837594518660128, 'norm': 'batch_norm', 'num_layers': 2}" --model=GIN:Sum --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=32 --dataset=PROTEINS --encoding_kwargs="{'embedding_dim': 64}" --k_fold=10 --k_wl=1 --lr=0.02390634549597559 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.04824676455149229, 'norm': 'batch_norm', 'num_layers': 3}" --model=1WL+NN:Embedding-Max --num_repition=5 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=32 --dataset=PROTEINS --encoding_kwargs="{'embedding_dim': 128}" --k_fold=10 --k_wl=1 --lr=0.0007727150111472792 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.04638997052917762, 'norm': 'batch_norm', 'num_layers': 3}" --model=1WL+NN:Embedding-Mean --num_repition=5 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=32 --dataset=PROTEINS --encoding_kwargs="{'embedding_dim': 16}" --k_fold=10 --k_wl=1 --lr=0.05977750052033193 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.08517859950618088, 'norm': 'batch_norm', 'num_layers': 2}" --model=1WL+NN:Embedding-Sum --num_repition=5 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=32 --dataset=PROTEINS --gnn_kwargs="{'act': 'relu', 'act_first': False, 'dropout': 0.023169054612438345, 'hidden_channels': 128, 'jk': 'cat', 'norm': None, 'num_layers': 5}" --k_fold=10 --k_wl=1 --lr=0.0002710194167602541 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.024331698859625252, 'norm': 'batch_norm', 'num_layers': 4}" --model=GIN:Max --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=32 --dataset=PROTEINS --gnn_kwargs="{'act': 'relu', 'act_first': False, 'dropout': 0.16510821539249532, 'hidden_channels': 32, 'jk': 'cat', 'norm': None, 'num_layers': 5}" --k_fold=10 --k_wl=1 --lr=0.0006646494970605938 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.10894450662250356, 'norm': 'batch_norm', 'num_layers': 4}" --model=GIN:Mean --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=32 --dataset=PROTEINS --gnn_kwargs="{'act': 'relu', 'act_first': False, 'dropout': 0.08541590257837439, 'hidden_channels': 16, 'jk': 'cat', 'norm': None, 'num_layers': 5}" --k_fold=10 --k_wl=1 --lr=0.001111690949810922 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.1587282961608454, 'norm': 'batch_norm', 'num_layers': 5}" --model=GCN:Sum --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
python Code/main.py --batch_size=32 --dataset=IMDB-BINARY --encoding_kwargs="{'embedding_dim': 16}" --k_fold=10 --k_wl=1 --lr=0.036295544195206385 --max_epochs=200 --mlp_kwargs="{'act': 'relu', 'dropout': 0.13678147258933218, 'norm': 'batch_norm', 'num_layers': 2}" --model=1WL+NN:Embedding-Sum --num_repition=5 --seed=42 --tags=replicate_run --wl_convergence=False
