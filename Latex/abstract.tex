\chapter*{Abstract}
Graphs are versatile data structures that model complex relationships in diverse fields, including social networks, biological systems, recommendation engines, and knowledge graphs. However, the flexibility of the graph data model poses challenges for applying machine learning techniques, as it lacks the constraints found in other data formats like images or text. In recent years, \textsf{Graph Neural Networks} (\gnns) have emerged as a promising approach for analyzing graphs, demonstrating exceptional empirical performance and versatility in various tasks and domains. Despite extensive studies on their theoretical expressiveness, a comprehensive understanding of the representations learned by \gnns and the factors contributing to their empirical success remains limited.

This thesis addresses the need for deeper insights into the representations learned by \gnns. To achieve this, we introduce a novel framework called \wlnn, which combines the Weisfeiler-Leman algorithm (\wl) with a feedforward neural network. The \wlnn framework serves as a powerful tool to study \gnns.

In this thesis, we prove the equivalence between the \wlnn framework and \gnns in terms of computability, enabling us to explore \gnns by conducting experiments on a variety of datasets for both \wlnn and \gnn models. Our results show that \wlnn models achieve comparable performance to \gnn models and even outperform them on certain datasets. However, \wlnn models tend to exhibit more pronounced overfitting, attributed to the expressive nature of the \wl algorithm. Interestingly, both \wlnn and \gnn models primarily rely on the information computed by a single iteration of the \wl algorithm, suggesting a trade-off between expressiveness and efficiency. Additionally, graph representations inferred by \gnn models demonstrate better linear separability and clustering compared to \wlnn models.

In conclusion, this thesis contributes to understanding \gnn representations and highlights the potential of the \wlnn framework as an analysis tool. The empirical insights gained from our experiments shed light on the inner workings of \gnn models, paving the way for further advancements in graph learning research. By better understanding the representations learned by \gnns, we can enhance their performance and applicability in real-world scenarios across various domains.