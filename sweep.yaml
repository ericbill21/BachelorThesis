method: random
metric:
  goal: maximize
  name: val_acc.max
parameters:
  activation_func:
    values:
      - relu
      - prelu
  batch_size:
    values:
      - 4
      - 8
      - 16
      - 32
      - 64
      - 128
  dataset:
    value: PROTEINS
  epochs:
    value: 200
  gnn_hidden_channels:
    values:
      - 2
      - 4
      - 8
      - 16
  gnn_layers:
    values:
      - 2
      - 4
      - 8
      - 16
  jk:
    value: cat
  k_fold:
    value: 5
  loss_func:
    value: CrossEntropyLoss
  lr:
    values:
      - 0.01
      - 0.02
      - 0.001
      - 0.002
  mlp_layer_size:
    values:
      - 8
      - 16
      - 32
      - 64
      - 128
  mlp_norm:
    value: batch_norm
  mlp_num_layers:
    values:
      - 1
      - 2
      - 3
      - 4
  model:
    values:
      - GIN:Mean
      - GIN:Max
      - GIN:Sum
  optimizer:
    values:
      - AdamW
      - SGD
  tags:
    value: sweep_gin
  transformer:
    value: ""
  transformer_args:
    value: ""
program: Code/main.py


program: Code/main.py
method: random
metric:
  name: val_acc.max
  goal: maximize
parameters:
  model:
    values: ["1WL+NN:Embedding-Set2Set"]
  dataset:
    value: "PROTEINS"
  epochs:
    value: 200
  batch_size:
    values: [4, 8, 16, 32, 128]
  lr:
    values: [0.01, 0.001, 0.002]
  k_fold:
    value: 5
  tags:
    value: "sweep_wlnn:set2set"
  optimizer:
    values: ["AdamW", "SGD"]
  mlp_layer_size:
    values: [8,16,32,64,128]
  mlp_num_layers:
    values: [1,2,4,8]
  wl_convergence:
    values: ["True", "False"]
  k_wl:
    value: 1
  loss_func:
    value: "CrossEntropyLoss"
  transformer:
    value: ""
  transformer_kwargs:
    value: "{}"
  activation_func:
    values: ["relu", "prelu"]
  mlp_norm:
    value: "batch_norm"
  encoding_kwargs:
    parameters:
      embedding_dim:
        values: [1, 2, 4, 8, 16]
  pool_func_kwargs:
    parameters:
      processing_steps:
        values: [1, 2, 4, 8]
      num_layers:
        values: [1, 2]